{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Translation with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to re-run from start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'archivo_chico.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=True, backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    samples = to_data(samples)\n",
    "    max_len_x,max_len_y = max([len(s[0]) for s in samples]),max([len(s[1]) for s in samples])\n",
    "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
    "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
    "    if backwards: pad_first = not pad_first\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            res_x[i,-len(s[0]):],res_y[i,-len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "        else:         \n",
    "            res_x[i,:len(s[0])],res_y[i,:len(s[1])] = LongTensor(s[0]),LongTensor(s[1])\n",
    "    if backwards: res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
    "    return res_x,res_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataBunch(TextDataBunch):\n",
    "    \"Create a `TextDataBunch` suitable for training an RNN classifier.\"\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1,\n",
    "               dl_tfms=None, pad_first=False, device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:\n",
    "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        collate_fn = partial(seq2seq_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTextList(TextList):\n",
    "    _bunch = Seq2SeqDataBunch\n",
    "    _label_cls = TextList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              pregunta    respuesta\n",
      "0     ¿cuál es tu principal habilidad?    ser feliz\n",
      "1            ¿practicas algún deporte?           si\n",
      "2                ¿cuál es tu favorito?    atletismo\n",
      "3  ¿cómo sería tu habitación perfecta?        no se\n",
      "4     ¿qué harías con el tiempo extra?   divertirme\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('archivo_chico.txt', sep=\",\")\n",
    "\n",
    "data['pregunta'] = data['pregunta'].apply(lambda x:x.lower())\n",
    "data['respuesta'] = data['respuesta'].apply(lambda x:x.lower())\n",
    "\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Config().model_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelLists;\n",
      "\n",
      "Train: LabelList (19 items)\n",
      "x: Seq2SeqTextList\n",
      "xxbos ¿ xxunk xxunk xxunk ?,xxbos ¿ cuál es tu xxunk ?,xxbos ¿ xxunk xxunk tu xxunk xxunk ?,xxbos ¿ qué xxunk xxunk xxunk xxunk xxunk ?,xxbos ¿ xxunk qué xxunk xxunk xxunk ?\n",
      "y: TextList\n",
      "xxbos xxunk,xxbos xxunk,xxbos xxunk xxunk,xxbos xxunk,xxbos xxunk xxunk\n",
      "Path: archivo_chico.txt;\n",
      "\n",
      "Valid: LabelList (4 items)\n",
      "x: Seq2SeqTextList\n",
      "xxbos ¿ cuál es xxunk xxunk xxunk xxunk xxunk xxunk xxunk ?,xxbos ¿ xxunk xxunk xxunk ?,xxbos ¿ cuál es tu xxunk xxunk ?,xxbos ¿ cuál es ?\n",
      "y: TextList\n",
      "xxbos xxunk xxunk xxunk xxunk,xxbos xxunk xxunk xxunk,xxbos xxunk xxunk,xxbos xxunk\n",
      "Path: archivo_chico.txt;\n",
      "\n",
      "Test: None\n"
     ]
    }
   ],
   "source": [
    "#emb_enc = torch.load(model_path/'fr_emb.pth')\n",
    "# emb_dec = torch.load(model_path/'en_emb.pth')\n",
    "\n",
    "src = Seq2SeqTextList.from_df(data, path = path, cols='pregunta').split_by_rand_pct(seed=42).label_from_df(cols='respuesta', label_cls=TextList)\n",
    "\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(out, targ, pad_idx=1):\n",
    "    bs,targ_len = targ.size()\n",
    "    _,out_len,vs = out.size()\n",
    "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
    "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
    "    return CrossEntropyFlat()(out, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_acc(out, targ, pad_idx=1):\n",
    "    bs,targ_len = targ.size()\n",
    "    _,out_len,vs = out.size()\n",
    "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
    "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
    "    out = out.argmax(2)\n",
    "    return (out==targ).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGram():\n",
    "    def __init__(self, ngram, max_n=5000): self.ngram,self.max_n = ngram,max_n\n",
    "    def __eq__(self, other):\n",
    "        if len(self.ngram) != len(other.ngram): return False\n",
    "        return np.all(np.array(self.ngram) == np.array(other.ngram))\n",
    "    def __hash__(self): return int(sum([o * self.max_n**i for i,o in enumerate(self.ngram)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grams(x, n, max_n=5000):\n",
    "    return x if n==1 else [NGram(x[i:i+n], max_n=max_n) for i in range(len(x)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_ngrams(pred, targ, n, max_n=5000):\n",
    "    pred_grams,targ_grams = get_grams(pred, n, max_n=max_n),get_grams(targ, n, max_n=max_n)\n",
    "    pred_cnt,targ_cnt = Counter(pred_grams),Counter(targ_grams)\n",
    "    return sum([min(c, targ_cnt[g]) for g,c in pred_cnt.items()]),len(pred_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(learn, ds_type=DatasetType.Valid):\n",
    "    learn.model.eval()\n",
    "    inputs, targets, outputs = [],[],[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in progress_bar(learn.dl(ds_type)):\n",
    "            out = learn.model(xb)\n",
    "            for x,y,z in zip(xb,yb,out):\n",
    "                inputs.append(learn.data.train_ds.x.reconstruct(x))\n",
    "                targets.append(learn.data.train_ds.y.reconstruct(y))\n",
    "                outputs.append(learn.data.train_ds.y.reconstruct(z.argmax(1)))\n",
    "    return inputs, targets, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusBLEU(Callback):\n",
    "    def __init__(self, vocab_sz):\n",
    "        self.vocab_sz = vocab_sz\n",
    "        self.name = 'bleu'\n",
    "    \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.pred_len,self.targ_len,self.corrects,self.counts = 0,0,[0]*4,[0]*4\n",
    "    \n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        last_output = last_output.argmax(dim=-1)\n",
    "        for pred,targ in zip(last_output.cpu().numpy(),last_target.cpu().numpy()):\n",
    "            self.pred_len += len(pred)\n",
    "            self.targ_len += len(targ)\n",
    "            for i in range(4):\n",
    "                c,t = get_correct_ngrams(pred, targ, i+1, max_n=self.vocab_sz)\n",
    "                self.corrects[i] += c\n",
    "                self.counts[i]   += t\n",
    "    \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        precs = [c/t for c,t in zip(self.corrects,self.counts)]\n",
    "        len_penalty = exp(1 - self.targ_len/self.pred_len) if self.pred_len < self.targ_len else 1\n",
    "        bleu = len_penalty * ((precs[0]*precs[1]*precs[2]*precs[3]) ** 0.25)\n",
    "        return add_metrics(last_metrics, bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherForcing(LearnerCallback):\n",
    "    def __init__(self, learn, end_epoch):\n",
    "        super().__init__(learn)\n",
    "        self.end_epoch = end_epoch\n",
    "    \n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        if train: return {'last_input': [last_input, last_target]}\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, **kwargs):\n",
    "        self.learn.model.pr_force = 1 - epoch/self.end_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_attn(nn.Module):\n",
    "    def __init__(self, emb_enc, emb_dec, nh, out_sl, nl=2, bos_idx=0, pad_idx=1):\n",
    "        super().__init__()\n",
    "        self.nl,self.nh,self.out_sl,self.pr_force = nl,nh,out_sl,1\n",
    "        self.bos_idx,self.pad_idx = bos_idx,pad_idx\n",
    "        self.emb_enc,self.emb_dec = emb_enc,emb_dec\n",
    "        self.emb_sz_enc,self.emb_sz_dec = emb_enc.embedding_dim,emb_dec.embedding_dim\n",
    "        self.voc_sz_dec = emb_dec.num_embeddings\n",
    "                 \n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(self.emb_sz_enc, nh, num_layers=nl, dropout=0.25, \n",
    "                              batch_first=True, bidirectional=True)\n",
    "        self.out_enc = nn.Linear(2*nh, self.emb_sz_dec, bias=False)\n",
    "        \n",
    "        self.gru_dec = nn.GRU(self.emb_sz_dec + 2*nh, self.emb_sz_dec, num_layers=nl,\n",
    "                              dropout=0.1, batch_first=True)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(self.emb_sz_dec, self.voc_sz_dec)\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "        self.enc_att = nn.Linear(2*nh, self.emb_sz_dec, bias=False)\n",
    "        self.hid_att = nn.Linear(self.emb_sz_dec, self.emb_sz_dec)\n",
    "        self.V =  self.init_param(self.emb_sz_dec)\n",
    "        \n",
    "    def encoder(self, bs, inp):\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, hid = self.gru_enc(emb, 2*h)\n",
    "        \n",
    "        pre_hid = hid.view(2, self.nl, bs, self.nh).permute(1,2,0,3).contiguous()\n",
    "        pre_hid = pre_hid.view(self.nl, bs, 2*self.nh)\n",
    "        hid = self.out_enc(pre_hid)\n",
    "        return hid,enc_out\n",
    "    \n",
    "    def decoder(self, dec_inp, hid, enc_att, enc_out):\n",
    "        hid_att = self.hid_att(hid[-1])\n",
    "        # we have put enc_out and hid through linear layers\n",
    "        u = torch.tanh(enc_att + hid_att[:,None])\n",
    "        # we want to learn the importance of each time step\n",
    "        attn_wgts = F.softmax(u @ self.V, 1)\n",
    "        # weighted average of enc_out (which is the output at every time step)\n",
    "        ctx = (attn_wgts[...,None] * enc_out).sum(1)\n",
    "        emb = self.emb_dec(dec_inp)\n",
    "        # concatenate decoder embedding with context (we could have just\n",
    "        # used the hidden state that came out of the decoder, if we weren't\n",
    "        # using attention)\n",
    "        outp, hid = self.gru_dec(torch.cat([emb, ctx], 1)[:,None], hid)\n",
    "        outp = self.out(self.out_drop(outp[:,0]))\n",
    "        return hid, outp\n",
    "        \n",
    "    def show(self, nm,v):\n",
    "        if False: print(f\"{nm}={v[nm].shape}\")\n",
    "        \n",
    "    def forward(self, inp, targ=None):\n",
    "        bs, sl = inp.size()\n",
    "        hid,enc_out = self.encoder(bs, inp)\n",
    "#        self.show(\"hid\",vars())\n",
    "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
    "        enc_att = self.enc_att(enc_out)\n",
    "        \n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            hid, outp = self.decoder(dec_inp, hid, enc_att, enc_out)\n",
    "            res.append(outp)\n",
    "            dec_inp = outp.max(1)[1]\n",
    "            if (dec_inp==self.pad_idx).all(): break\n",
    "            if (targ is not None) and (random.random()<self.pr_force):\n",
    "                if i>=targ.shape[1]: continue\n",
    "                dec_inp = targ[:,i]\n",
    "        return torch.stack(res, dim=1)\n",
    "\n",
    "    def initHidden(self, bs): return one_param(self).new_zeros(2*self.nl, bs, self.nh)\n",
    "    def init_param(self, *sz): return nn.Parameter(torch.randn(sz)/math.sqrt(sz[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "hid=torch.Size([2, 64, 300])\n",
    "dec_inp=torch.Size([64])\n",
    "enc_att=torch.Size([64, 30, 300])\n",
    "hid_att=torch.Size([64, 300])\n",
    "u=torch.Size([64, 30, 300])\n",
    "attn_wgts=torch.Size([64, 30])\n",
    "enc_out=torch.Size([64, 30, 512])\n",
    "ctx=torch.Size([64, 512])\n",
    "emb=torch.Size([64, 300])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emb_enc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-467c92da88e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeq2SeqRNN_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m learn = Learner(data, model, loss_func=seq2seq_loss, metrics=[seq2seq_acc, CorpusBLEU(len(data.y.vocab.itos))],\n\u001b[1;32m      3\u001b[0m                 callback_fns=partial(TeacherForcing, end_epoch=30))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'emb_enc' is not defined"
     ]
    }
   ],
   "source": [
    "model = Seq2SeqRNN_attn(emb_enc, emb_dec, 256, 30)\n",
    "learn = Learner(data, model, loss_func=seq2seq_loss, metrics=[seq2seq_acc, CorpusBLEU(len(data.y.vocab.itos))],\n",
    "                callback_fns=partial(TeacherForcing, end_epoch=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>seq2seq_acc</th>\n",
       "      <th>bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.887606</td>\n",
       "      <td>3.718430</td>\n",
       "      <td>0.556508</td>\n",
       "      <td>0.341307</td>\n",
       "      <td>01:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.506591</td>\n",
       "      <td>3.122954</td>\n",
       "      <td>0.551054</td>\n",
       "      <td>0.402871</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.548055</td>\n",
       "      <td>3.860026</td>\n",
       "      <td>0.473495</td>\n",
       "      <td>0.410226</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.735435</td>\n",
       "      <td>3.202152</td>\n",
       "      <td>0.529949</td>\n",
       "      <td>0.441509</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.808599</td>\n",
       "      <td>3.711476</td>\n",
       "      <td>0.472057</td>\n",
       "      <td>0.408111</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.891013</td>\n",
       "      <td>3.141925</td>\n",
       "      <td>0.523613</td>\n",
       "      <td>0.437650</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.952281</td>\n",
       "      <td>3.402686</td>\n",
       "      <td>0.485307</td>\n",
       "      <td>0.413826</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.096382</td>\n",
       "      <td>3.790361</td>\n",
       "      <td>0.442190</td>\n",
       "      <td>0.379218</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.994412</td>\n",
       "      <td>3.421550</td>\n",
       "      <td>0.474625</td>\n",
       "      <td>0.396157</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.207710</td>\n",
       "      <td>3.459248</td>\n",
       "      <td>0.473342</td>\n",
       "      <td>0.392821</td>\n",
       "      <td>01:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.987739</td>\n",
       "      <td>3.538437</td>\n",
       "      <td>0.468906</td>\n",
       "      <td>0.380963</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.819864</td>\n",
       "      <td>3.483137</td>\n",
       "      <td>0.479421</td>\n",
       "      <td>0.392705</td>\n",
       "      <td>01:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.412151</td>\n",
       "      <td>3.555584</td>\n",
       "      <td>0.479795</td>\n",
       "      <td>0.396348</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.363241</td>\n",
       "      <td>3.424492</td>\n",
       "      <td>0.496230</td>\n",
       "      <td>0.408865</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.452292</td>\n",
       "      <td>3.420485</td>\n",
       "      <td>0.498205</td>\n",
       "      <td>0.413232</td>\n",
       "      <td>01:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(15, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='151' class='' max='151', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [151/151 00:34<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs, targets, outputs = get_predictions(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos qui a le pouvoir de modifier le règlement sur les poids et mesures et le règlement sur l'inspection de l'électricité et du gaz ?,\n",
       " Text xxbos who has the authority to change the electricity and gas inspection regulations and the weights and measures regulations ?,\n",
       " Text xxbos what do we regulations and and regulations ? ?)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[700], targets[700], outputs[700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos ´ ` ou sont xxunk leurs grandes convictions en ce qui a trait a la ` ` ´ transparence et a la responsabilite ?,\n",
       " Text xxbos what happened to their great xxunk about transparency and accountability ?,\n",
       " Text xxbos what are the and and and and and and and and and to to ? ?)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[701], targets[701], outputs[701]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos quelles ressources votre communauté possède - t - elle qui favoriseraient la guérison ?,\n",
       " Text xxbos what resources exist in your community that would promote recovery ?,\n",
       " Text xxbos what resources would your community community community community community community ?)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[4002], targets[4002], outputs[4002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
